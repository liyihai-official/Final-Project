% \documentclass[manuscript,screen,review]{acmart}
% \documentclass[sigconf, screen, final, language=english, natbib=false]{acmart}
\documentclass[manuscript, screen, review, language=english, natbib=false]{acmart}
\usepackage{subfigure, wrapfig}
\usepackage{algorithm, algorithmic}
\usepackage{listings}
\usepackage{color} % use color
\usepackage{pgfplots}
\usetikzlibrary{3d,arrows.meta,shapes.geometric}
\usepackage{lipsum}
\usepackage{multirow}
\usepackage{array}

\usepackage{forest}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=C++, % C++
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=left,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\lstdefinestyle{customCpp}{
  language=C++,                 % 使用C++语言高亮
  frame=tb,                     % 代码块上下有边框
  aboveskip=3mm,                % 代码块上方间距
  belowskip=3mm,                % 代码块下方间距
  showstringspaces=false,       % 不显示字符串中的空格
  columns=flexible,             % 列宽度为可调节
  basicstyle={\small\ttfamily}, % 基本样式为小号等宽字体
  numbers=left,                 % 行号显示在左侧
  numberstyle=\tiny\color{gray},% 行号的样式为灰色小号字体
  keywordstyle=\color{blue},    % 关键字的颜色为蓝色
  commentstyle=\color{dkgreen}, % 注释的颜色为深绿色
  stringstyle=\color{mauve},    % 字符串的颜色为紫红色
  breaklines=true,              % 代码过长时自动换行
  breakatwhitespace=true,       % 只在空格处换行
  tabsize=2,                    % 制表符宽度为4个空格
  captionpos=b,                 % 标题位置在代码块底部
  keepspaces=true,              % 保留空格
  escapeinside={\%*}{*)},       % 可以在代码中插入LaTeX
  morekeywords={constexpr, nullptr, size_type, Integer, \&, MPI_Type_create_subarray}, % 添加自定义关键字
}


\usepackage{tikz}

\tikzstyle myBG=[line width=3pt,opacity=1.0]
\newcommand{\myGlobalTransformation}[2]
{
  \pgftransformcm{1}{0}{0.5}{0.4}{\pgfpoint{#1em}{#2em}}
}

\newcommand{\gridThreeD}[3]
{
  \begin{scope}
    \myGlobalTransformation{#1}{#2};
    \draw [#3,step=1.5em] grid (12,12);
  \end{scope}
}

\newcommand{\drawLinewithBG}[2]
{
  \draw[white,myBG]  (#1) -- (#2);
  \draw[dashed, black,thick] (#1) -- (#2);
}
\newcommand{\graphLinesHorizontal}
{
  \drawLinewithBG{1,1}{7,1};
  \drawLinewithBG{1,2.5}{7,2.5};
  \drawLinewithBG{1,4}{7,4};
  \drawLinewithBG{1,5.5}{7,5.5};
  \drawLinewithBG{1,7}{7,7};
}

\newcommand{\graphLinesVertical}
{
  \pgftransformcm{0}{1}{1}{0}{\pgfpoint{0em}{0em}}
  \graphLinesHorizontal;
}

\newcommand{\graphThreeDnodes}[2]
{
  \begin{scope}
    \myGlobalTransformation{#1}{#2};
    \foreach \x in {1,2.5,4,5.5,7} 
    {
      \foreach \y in {1,2.5,4,5.5,7} 
      {
\node at (\x,\y) [circle,fill=black,scale=0.45] {};
      }
    }
  \end{scope}
}

%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}



\setcopyright{none}

\copyrightyear{2024}
\acmYear{2024}
\acmDOI{}
\acmISBN{}

\acmConference[MAP55640]{Final Project}{May 25, 2024}{Dublin, Ireland}

% Bibliography style
\RequirePackage[
  datamodel=acmdatamodel,
  style=acmnumeric,
  ]{biblatex}

% %% Declare bibliography sources (one \addbibresource command per source)
\addbibresource{reference.bib}





\begin{document}
\title[Final Project]{MAP55640 - 
Comparative Analysis of Hybrid-Parallel Finite Difference Methods on Multicore Systems 
and 
Physics-Informed Neural Networks on CUDA Systems}


\author{Li Yihai}
\email{liy35@tcd.ie}
% \authornote{}
\affiliation{%    
    \institution{Mathematics Institute}
    \institution{High Performance Computing}
    \city{Dublin}
    \country{Ireland}
}

\author{Mike Peardon}
\authornote{Supervisor of this Final Project}
\email{mjp@maths.tcd.ie}
\affiliation{    
  \institution{Mathematics Institute}
  \institution{High Performance Computing}
  \city{Dublin}
  \country{Ireland}
}


\settopmatter{printacmref=false}


% \begin{abstract}
%   % This is the abstract of this project.

%   % \lipsum[2-4]
%   Finite Difference Methods is a fundamental numerical method for solving partial differential equations.
%   For the large scale discretized system, the high-performance parallel solver which 
%   make fully use of the compute resources is still highly required.
%   作为纯MPI程序，程序之间的交流、同步往往是程序的瓶颈，所以现在更常见的策略是混合并行策略，即
%   同时考虑信息交流并行和共享内存并行。
%   另一种GPU并行同样是一种常见的选择，其中更为主流的是PINN作为仿真器来解决物理问题或者通过测试数据来逆向求解物理参数。
%   本文首先结合C++特性设计了更为安全的、高效的N维矩阵模板类和相应MPI N维笛卡尔拓扑结构交流环境。
%   对于求解热传导方程提出了3种CPU并行策略，分别实现了纯MPI并行，以及结合OpenMP实现了无计算交流重叠的master-only的并行方式，以及有交流重叠的master-only的并行方式。
%   构建了解决热传导方程的PINN，并且结合CUDA技术实现了GPU加速训练。
%   最终对3种CPU并行策略进行Weak/Strong Scaling测试分析在不同节点下的性能差异，以及将时间消耗、最终结果的精确度作为参考，与PINN进行对比。

% \end{abstract}
    

\begin{abstract}
The Finite Difference Method (FDM) is a fundamental numerical technique for solving partial differential equations (PDEs). For large-scale discretized systems, there remains a strong demand for high-performance parallel solvers that fully utilize computational resources. As a pure MPI program, communication and synchronization between processes often become bottlenecks, leading to the increased adoption of hybrid parallel strategies, which consider both message-passing parallelism and shared memory parallelism.

Another common choice for parallelism is GPU computing, where Physics-Informed Neural Networks (PINNs) have emerged as a mainstream approach for solving physical problems or for inverse solving of physical parameters based on test data. In this paper, we first design a safer and more efficient N-dimensional matrix template class, utilizing C++ features, along with a corresponding MPI N-dimensional Cartesian topology communication environment.

For solving the heat conduction equation, three CPU parallel strategies are proposed: 
pure MPI parallelism, master-only parallelism without computation/communication overlap using MPI and OpenMP, 
and master-only parallelism with computation/communication overlap. Additionally, we constructed a PINN to 
solve the heat conduction equation and employed CUDA technology to implement GPU-accelerated training.

Finally, weak and strong scaling tests are conducted on the three CPU parallel strategies to analyze performance differences across various nodes. 
The time consumption and accuracy of the final results are compared with those of the PINN as references.

\end{abstract}

% Keywords. The author(s) should pick words that accurately describe
% the work being presented. Separate the keywords with commas.
\keywords{
    Keywords
}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

% ------------------------------------------------------------------------------------------------

\include{chapter/introduction}
\include{chapter/relatedwork}
\include{chapter/problemstatement}
\include{chapter/methedology}
\include{chapter/implementation}

% \section{Acknowledgement}
\include{chapter/further}


% \bibliographystyle{ACM-Reference-Format}
% \bibliography{reference}

\printbibliography

% \newpage
\appendix
% \addcontentsline{toc}{section}{Appendix}
% \section{Appendix}
\section{Implementation Details}\label{APP:IMPLEMENTATION}
\begin{table}[htbp]
  \caption{Configuration of PINN}
  \label{TAB:BConfiguration_of_PINN}
  \begin{minipage}{\columnwidth}
    \begin{center}
        \begin{tabular}{lc}
            \toprule
            \bfseries Module   &  \bfseries value \\
            \midrule
            Dimension & $2$, $3$ \\
            tolerance & $0.01$, $0.0001$ \\
            Dense & $h$ \\
            Data type & \texttt{float32} \\
            Activation Function & $\tanh$ \\
            Input size & Dimension \\
            Output size & 1 \\
            Optimizer & Adam \\
            learning rate decay & None \\
            learning rate & 0.001 \\
            dataset size & $16896$, $2 \times 10^6$ \\
            max epochs  & $1000 000$ \\
            batch size & full dataset \\
            \bottomrule
        \bottomrule
      \end{tabular}
    \end{center}
    % \bigskip
    % \footnotesize\emph{Source:} This is source 
  \end{minipage}
\end{table}
The network structure of PINN is shown in the figure \ref{FIG_Schematic_View_PINN}, that is the $h$ is the 
number of neuraons in each hidden layers.
The input size of PINN is depending on the dimension of 
heat equation, as well as the dataset size.
The Adam optimizer has a learning rate without decay 
strategy. 
This is a small model, thus I did not chose to use batch size for 
these training tasks.


\section{File Tree}\label{APP:FOLDER}
\begin{forest}
for tree={
    grow=east,            % 树从左往右生长
    parent anchor=east,   % 父节点的锚点设在右边
    child anchor=west,    % 子节点的锚点设在左边
    font=\ttfamily,
    anchor=west,          % 每个节点相对于其锚点对齐
    edge path={\noexpand\path[\forestoption{edge}](!u.east)--(.west)\forestoption{edge label};}, % 边的样式
    inner sep=1pt,        % 内间距
    l sep=10pt,           % 子节点与父节点之间的水平距离
    s sep=2pt             % 子节点间的垂直距离
}
[Project Root
    [CMakeLists.txt]
    [Doxyfile]
    [README.md]
    [config.h.in]
    [include
        [assert.hpp]
        [helper.hpp]
        [mpi
            [assert.hpp]
            [environment.hpp]
            [multiarray.hpp]
            [topology.hpp]
            [types.hpp]
        ]
        [multiarray
            [base.hpp]
            [types.hpp]
        ]
        [multiarray.hpp]
        [pde
            [Heat.hpp]
            [details
                [BoundaryConditions
                    [BoundaryConditions\_2D.hpp]
                    [BoundaryConditions\_3D.hpp]
                ]
                [Heat\_2D.hpp]
                [Heat\_3D.hpp]
                [InitializationsC.hpp]
            ]
            [pde.hpp]
        ]
        [pinn
            [dataset.hpp]
            [helper.hpp]
            [pinn.hpp]
            [types.hpp]
        ]
        [types.hpp]
    ]
    [main1
        [main1.cpp]
        [main1\_3d.cpp]
    ]
    [main2
        [datagen.cpp]
        [main2.cpp]
        [pred.cpp]
    ]
    [src
        [boundary.m]
        [helper.cpp]
        [loadFromBinary.m]
        [pinn
            [dataset.cpp]
            [helper.cpp]
        ]
        [saveToBinary.m]
        [vis2d.m]
        [vis3d.m]
        [visdataset.m]
    ]
]
\end{forest}

\end{document}

\section{Methedology}
\subsection{General Setups}
Initially, we need to determine the data types to be used and define macros for 
assertions and helper functions to ensure that the program can detect common bugs 
and report their locations. 
These features can also be disabled in the release version for performance optimization. 
Such details are defined in the \texttt{assert.hpp}, \texttt{helper.hpp}, 
and other related header files located in the subfolder.

\subsection{Template Multi-dimension Matrix Detail Design}
The FDTD method is a type of FDM. 
The main idea behind FDM is briefly outlined in Section \ref{SEC:FDM}. 
The challenge lies in implementing it in a computer system to ensure it runs both correctly and efficiently.
Also, the data types I am using for storing sizes are unit32\_t and unit64\_t while I used them 
as Dworld and Qworld respectively, also are defined as size\_type and super\_size\_type in \_\_detail namespace.

\subsubsection{Performance Balancing}
\paragraph{Template Class}
Instead of doing this by using hierarchy in C++, which will cause the memory of object becomes complicated and unpredictable,
and leading to scattered data members between base and derived class objects.
This scattering can increase the cache misses which accessing these members, as the data might not be contiguous in memory.
Also, with deep inheritance hierarchies, program has higher change to occur diamond problems, since it increases the code complexity.
In detail, the diamond problem leads the duplicate inheritance and ambiguity in the method resolution, which will drop performance down again.
Although, it is solvable by using \texttt{virtual} inheritance, but again, it increase the complexity.

In such case, I chose to use template class to design the matrix object, which implement compile-time polymorphism as opposed runtime polymorphism
provided by inheritance and virtual functions. 
With such template design, the compiler makes the decisions about which function or class instantiate is made at compile time, eliminating 
the need for \texttt{vtable}s and indirect function calls, which leads to more efficient code. 

\paragraph{Memory Management}
Rather than using the standard library's (STL) vector module, 
which can be slower due to the overhead of row pointers, 
I opted to build the Matrix object using a unique pointer 
(
  \texttt{std::unique\_ptr}
), which includes only basic features such as reset, swap, and most importantly, 
a destructor that automatically deletes pointers. 
This approach enhances the safety of memory management in our programs.
Additionally, from a safety perspective, 
given that I implemented many features within the matrix object, 
I followed standard library conventions for naming. 
This includes using the \texttt{\_\_detail} namespace within namespace \texttt{multi\_array} to 
hide objects and features that are not intended for direct use by the end user.

\subsubsection{Template Object Design of Matrix Shape}

\paragraph{Strides} 
Besides that, in the multidimensional cases, the size in each dimension is not enough for accessing 
variables, this is where we need the \texttt{strides} member variable, which stores the 
number of element the operator needs to skip in each dimension.
The \texttt{\_\_multi\_array\_shape} object is encapsulated within 
the \texttt{\_\_detail} namespace and serves as a member variable of the later template object for the multi-dimensional matrix. 
This object includes a member variable defined using the STL vector, as the shape object primarily stores the sizes for each dimension, 
which typically requires only a small amount of space. 
Additionally, this object provides member functions to access the size of a given dimension. 
\begin{algorithm}
  \caption{Stride implementation}
  \begin{algorithmic}[1]
    \STATE \texttt{dims}    \hfill \# STL vector, stores the matrix's size in each dimension.
    \STATE \texttt{strides} \hfill \# STL vector, has the same size with dims.
    \STATE n = dims.size()  \hfill \# Store the dimension of matrix.
    \STATE strides[d-1] = 1; \hfill \# Stride is 1 in the first dimension.
    \FOR{ d = n - 1; d > 0; --d }     
      \STATE strides[d-1] = strides[d] * dims[d] \hfill \# Determine stride in the latter dimension.
    \ENDFOR
    \RETURN \texttt{strides}
  \end{algorithmic}
\end{algorithm}


\paragraph{Performace Balancing}
In certain scenarios, 
we only require the shape information of a matrix without needing to access the entire matrix object. 
Accessing the shape information through well-defined operators is a more efficient way to 
handle multidimensional matrices. 
This is particularly crucial in parallel programming, where understanding 
the shape of a matrix is of critical importance. 
Sometimes, a process may need to know the shape of matrices stored on other processes. 
In such cases, using this matrix object as a local variable within functions increases the 
likelihood that the compiler will store it in a register, 
which is generally faster than using heap or stack memory.
In addition, it includes check and cast functions that allow the user to verify if the template data type \texttt{\_\_T} is signed using \texttt{constexpr}. 
The \texttt{constexpr} keyword ensures that this check occurs at compile time, and if the data type is not legal, 
the program will assert and provide a message indicating that the indexing value must be a non-negative number. 


\subsubsection{Template of Multi-dimensional Matrix Implementation}
The Matrix in this project is designed to support various data types in C++. 
Consequently, the matrix is implemented as a template class with several essential features, template 
variable \texttt{\_\_T} and \texttt{\_\_NumD}, for the value data type and number of dimension, 
also including iterators, swap functionality, fill operations, and support for the IO stream operator \texttt{<<}. 
To facilitate this, the \texttt{\_\_array\_shape} object is used to explicitly manage and access the array's shape information. 


\paragraph{Operator \texttt{()}}
The hard part of this object designed is the support template number of dimension, whereas the dimension 
is integer not less than $1$,
the operator of access element is designed by following algorithm
\begin{algorithm}
  \caption{Operator \texttt{(Ext ... exts)} of template matrices object \texttt{\_\_detail::\_\_array}}
  \begin{algorithmic}[1]
    \STATE \texttt{\_\_NumD}, \texttt{\_\_T};                   \hfill \# Template variables: dimension, data type.
    \STATE \texttt{FINAL\_PROJECT\_ASSERT\_MSE}                 \hfill \# Number of Arguments must Match the dimension.
    \STATE \texttt{index} = 0, \texttt{i} = 1                \hfill \# Initialize variables in advance.
    \STATE \texttt{indices[] = \_\_shape.check\_and\_cast(ext)}          \hfill \# The indexes number must none-negative number.
    \FOR{i < \texttt{\_\_NumD}; ++i}
      \STATE \texttt{index += indices[i] * \_\_shape.strides[i]} 
    \ENDFOR
    \STATE \texttt{FINAL\_PROJECT\_ASSERT\_MSE}           \hfill \# Boundary checking.
    \RETURN \texttt{\_\_data[index]}
  \end{algorithmic}
\end{algorithm}

\paragraph{Overload operator \texttt{<<}}
In order to print the multi-dimension array with operator \texttt{<<}, I designed a recursive helper function
to print the matrix on given dimension. Thus we could call the function on the first dimension, and it will 
recursively print all dimensions.
\begin{algorithm}
  \caption{Recursive Function to Print Multi-Dimensional Array}
  \begin{algorithmic}[1]
    \STATE \texttt{current\_dim}, \texttt{offset};               \hfill \# Parameters: current dimension, offset.
    \STATE \texttt{Dims} \texttt{\_\_Dims};                       \hfill \# Template variable: number of dimensions.
    \IF{\texttt{current\_dim == \_\_Dims - 1}}
      \STATE \texttt{os << "|"}                                   \hfill \# Start printing last dimension.
      \FOR{$i$ \texttt{ from 0 to arr.\_\_shape[current\_dim] - 1}}
        \STATE \texttt{os << std::fixed << std::setprecision(5) << std::setw(9) << arr.\_\_data[offset + i];} \hfill \# Print array elements with formatting.
      \ENDFOR
      \STATE \texttt{os << " |\textbackslash n";}                  \hfill \# End of current row in the last dimension.
    \ELSE
      \FOR{$i$ \texttt{ from 0 to arr.\_\_shape[current\_dim] - 1}}
        \STATE \texttt{next\_offset = offset;}                      \hfill \# Initialize next offset.
        \FOR{$j$ \texttt{ from current\_dim + 1 to \_\_Dims - 1}}
          \STATE \texttt{next\_offset *= arr.\_\_shape[j];}          \hfill \# Update next offset based on shape.
        \ENDFOR
        \STATE \texttt{next\_offset += i * arr.\_\_shape[current\_dim + 1];} \hfill \# Finalize next offset for recursion.
        \STATE \texttt{self(self, arr, current\_dim + 1, next\_offset);} \hfill \# Recursive call to print next dimension.
      \ENDFOR
      \STATE \texttt{os << "\textbackslash n";}                     \hfill \# Print a newline after each dimension.
    \ENDIF
  \end{algorithmic}
\end{algorithm}



\subsection{Template Multi-dimension Matrix Interface Design}
With contiguity of safety, this object of multi-dimension array is accessible to users without 
direct visit to the memory space where store values of matrix.

\subsubsection{Resource Acquisition Is Initialization (RAII)}
This private object has only a member variable, a unique pointer to the template \texttt{\_\_array}, 
and other member function provide necessary features to operating on it.
Smart pointers acquire resources in their constructor and automatically release them in their destructor, 
which is the essence of RAII. 
By releasing resources in the destructor, smart pointers help prevent resource leaks.
When an exception occurs, smart pointers automatically release resources, preventing resource leaks,
thus it enhanced the safety level of using resources, reduce the potential memory leak problems.


\subsubsection{Template Multi-dimension IO for writing to/reading from file}
Initially, the multi-dimension matrix has variables shape, 
and values which given dimension and size in each dimension.
This template design end up with these variable can be stored in given data types also leads with lower 
portability.
To avoid such problems and from other point of views, I chose to store the matrices in binary format, 
rather than other type files.
There are couple benefits of doing so,
\begin{enumerate}
  \item 	Compatibility and Portability: The format of binary files is relatively 
  stable and can be easily used in different programming environments or applications. 
  Unlike \texttt{.txt} files, \texttt{.mat} files those has less compatibility across different platforms.
  \item I/O Performance: Binary files can perform block-level I/O operations directly 
  without needing to parse text formats or convert data types. 
  This usually makes reading and writing binary files much faster than \texttt{.txt} files, 
  especially when dealing with large-scale multidimensional matrix data.
  \item Support MPI IO: Binary files support the MPI IO, which provides a significant reduction in the 
  cost of communication, when storing and reading the large scale matrices. 
\end{enumerate}
However, the IO does not play a critical role in effects performance of FDTD algorithms, if and only if 
we need to store or load the data during evolving the arrays.

\subsection{MPI Parallel Environment Design Scheme}
\subsubsection{MPI Setups}
\paragraph{Environment}
Similar to how \texttt{malloc} in C and \texttt{new} in C++ require manual memory management, 
the MPI environment also necessitates explicit initialization and finalization. 
However, unlike the efficient implementation of smart pointers in the STL, 
Boost.MPI\cite{BOOST_MPI}
-a high-level parallelism libraryâ€”
may not be the optimal choice for high-performance programs. 
Therefore, I chose to design a custom MPI environment that encapsulates the necessary features specific to this project.

The \texttt{mpi} namespace, a sub-namespace of \texttt{final\_project}, provides the \texttt{environment} class. 
This class integrates MPI initialization using the constructor, which invokes \texttt{MPI\_Init\_thread},
provides multi-threading shared memory parallelism in MPI, 
and MPI finalization through the destructor, which calls \texttt{MPI\_Finalize}.

It also offers direct access to the rank and the number of processors within the MPI communicator.
Furthermore, I have explicitly deleted the copy and move assignment operators to enhance safety. 
This design decision aligns with the RAII principle, 
ensuring that MPI environment resources are automatically managed, thereby preventing leaking and 
using-uninitialized problems.

\paragraph{Types and Assertions} 
Aligned meta-programming with polymorphism principles, 
I designed a template function to retrieve the corresponding MPI basic data types, 
leveraging the fundamental data types I defined as traits at the outset.
Moreover, I provides some MPI macros in assert file, 
these macros provide a unified interface for dealing with MPI-related errors,
ensuring that MPI errors are handling consistently, safely. 

\subsubsection{MPI Topology (\texttt{Cartesian})}
The namespace \texttt{topology} is a sub-namespace of \texttt{mpi}, 
the template Cartesian structure is the mainly used object in following 
problems.
To optimize memory usage, this object maintains only essential multi-dimension matrices' global and local shape member variables.
It also contains a MPI Communicator and MPI value data type, halo data type along with the neighbors' rank in the source and dest sites.
To ensure the MPI security, the copy and move constructors as well as assignment operators are manually removed.
Additionally, the destructor is customized for properly release halo data type and Cartesian communicator. 


\paragraph{Determine the local matrix's localtion}
Evenly distributing tasks across processes is of critical importance.
To address this, I designed an algorithm to divide an integer $N$ evenly to $n$ clients, where I could put it in use in 
many cases.
Rather than implementing a standalone function, I chose to implement a lambda function, which is a feature in C++ that do not significantly 
impact the performance.
It allows me to design a small function which is not frequently use or play a key role in performance.
\begin{algorithm}
  \caption{Lambda Function (decomposition): Split tasks evenly to $n$ processes evenly}
  \begin{algorithmic}[1]
    \STATE \texttt{n, rank} \hfill \# const Integers, total number and current rank of Processor.
    \STATE \texttt{N} \hfill \# constant Integer, Problem size.
    \STATE \texttt{s, e} \hfill \# Integer, start, end indexes.
    \STATE \texttt{n\_loc = n / N} \hfill \# Divide the problem evenly.
    \STATE \texttt{remain = n \% N} \hfill \# Get the remaining tasks.
    \STATE \texttt{s = rank * n\_loc + 1} \hfill \# Calculate the start indexes.
    \IF{\texttt{rank < remain}}      
      \STATE \texttt{s += rank}      \hfill \# Give a task to process the rank is smaller than remain.
      \STATE \texttt{++n\_loc}       \hfill \# Update local number of tasks.
    \ELSE 
      \STATE \texttt{s += remain}   \hfill \# Add the remain to start index, after split remains.
    \ENDIF
    \STATE \texttt{e = s + n\_loc + 1}  \hfill \# Get the ending indexes
    \IF{\texttt{e > n} \OR \texttt{rank == N - 1}} 
      \STATE \texttt{e = n}           \hfill \# If it is the end of all.
    \ENDIF
  \end{algorithmic}
\end{algorithm}
Ideally, this function will be only called when I construct the MPI topology based multi-dimension array, where I 
need cut the global matrix's shape evenly and create local matrices with local shape.
Using local shape to create local matrices is obviously a memory-saving techniques when the problem size gets larger.
Eventually, the lambda function is only applied in constructor of template Cartesian structure, which constructed from 
an input global and a MPI topology environment. 

Moreover, the topology information is determined by \texttt{MPI\_Cart\_coords} for the coordinates and \texttt{MPI\_Cart\_shift} 
the neighbors of each process in all dimension. 
Below is a example [Fig. \ref{FIG_MPI_TOPOLOGY_24_PROCS}] of cartesian topology of $24$ processors, with no period in all dimensions.
\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}
    \draw[help lines, step=1em] (0,0) grid (-20em, -20em);
    \draw[thick, ->] (0,0) -- (-20em, 0) node[left] {$x$};
    \draw[thick, ->] (0,0) -- (0, -20em) node[below] {$y$};
    
    \def\xsize{2};
    \def\ysize{3};
    \def\zsize{4};
  
    \begin{scope}[shift={(-15em, -15em)}, x={(2em,-0.25em)},y={(0em,2em)}, , z={(-1.25em,-0.5em)}]
      % Draw the front face
      \fill[blue!20] (0,0,0) -- (0,\ysize,0) -- (\zsize, \ysize,0) -- (\zsize,0,0) -- cycle;
      % Draw the top face
      \fill[blue!40] (0,\ysize,0) -- (0,\ysize,-\xsize) -- (\zsize, \ysize, -\xsize) -- (\zsize, \ysize,0) -- cycle;
      % Draw the right face
      \fill[blue!60] (\zsize,0,0) -- (\zsize,0,-\xsize) -- (\zsize, \ysize, -\xsize) -- (\zsize, \ysize,0) -- cycle;
  
      \foreach \x in {0,1, ..., \xsize}
      {
        \draw[black] (0, \ysize, -\x/\xsize * \xsize) -- (\zsize, \ysize, -\x/\xsize * \xsize);
        \draw[black] (\zsize,0,-\x/\xsize * \xsize) -- (\zsize, \ysize,-\x/\xsize * \xsize);
      }
  
      \foreach \y in {0, 1, ..., \ysize}
      {
        \draw[black] (0,\y/\ysize * \ysize,0) -- (\zsize,\y/\ysize * \ysize,0);
        \draw[black] (\zsize,\y/\ysize * \ysize,0) -- (\zsize,\y/\ysize * \ysize,-\xsize);
      }
  
      \foreach \z in {0, 1, ..., \zsize}
      {
        \draw[black] (\z/\zsize * \zsize,\ysize,0) -- (\z/\zsize * \zsize,\ysize,-\xsize);
        \draw[black] (\z/\zsize * \zsize,0,0) -- (\z/\zsize * \zsize,\ysize,0);
      }
    \end{scope}
  \end{tikzpicture}
  \caption{An example of MPI Cartesian topology Scheme of $24$ processors.}
  \label{FIG_MPI_TOPOLOGY_24_PROCS}
\end{figure}

\paragraph{Determine MPI datatypes for communication}
In order to do MPI communications, the source and the destination of every process are necessary, also the datatype.
When working with the meta-designed multidimensional matrix, we need to utilize the function \texttt{MPI\_Type\_Create\_subarray} to 
create essential halo datatypes.
\begin{algorithm}
  \begin{algorithmic}[1]
    \STATE \texttt{array\_size}, \texttt{array\_subsize}, \texttt{array\_starts=\{0\}} \hfill \#\texttt{std::array<Integer, NumD>}, the information of matrix.
    \FOR {i = 0 : NumD}
      \STATE Split tasks in dimension \texttt{i} by calling \texttt{decomposition}
      \STATE \texttt{array\_size = }local shape
      \STATE \texttt{array\_subsize = array\_size - 2}
    \ENDFOR
    \FOR {i=0 : NumD}
      \STATE \texttt{temp = array\_subsize[i]} \hfill \# Store the number temporally.
      \STATE \texttt{array\_subsize[i] = 1}
      \STATE \texttt{MPI\_Type\_Create\_subarray
      } and \texttt{MPI\_Type\_commit()} \hfill \# Create halo in dimension \texttt{i} and commit.
      \STATE Restore temporal array sub-size.
    \ENDFOR
  \end{algorithmic}
\end{algorithm}

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}
    % Draw a grid with steps of 1 cm
    \draw[help lines, step=1em] (-10em,-10em) grid (30em,30em);
  
    % Draw axes
    \draw[dashed,->] (-10em,0) -- (30em,0) node[right] {x};
    \draw[dashed,->] (0,-10em) -- (0,30em) node[above] {y};
  
    \draw[thick,->] (5em, 28em) -- (-5em, 23em) node[pos=0, above] {$source$} node[pos=0.5, above] {$dim_0$} node[pos=1, above] {$dest$};
    \draw[thick,->] (-3em, 18em) -- (-3em, 4em) node[pos=0, above] {$source$} node[pos=0.5, left] {$dim_1$} node[pos=1, below] {$dest$};
    \draw[thick,->] (14em, 28.5em) -- (28em, 27em) node[pos=0, above] {$source$} node[pos=0.5, above] {$dim_2$} node[pos=1, above] {$dest$};
  
      % Define a local macro to draw a cube at a given position
      \def\drawcube#1#2{
        \begin{scope}[shift={#1}, x={(0.8em,-0.1em)}, y={(0em,0.8em)}, z={(0.4em,0.20em)}]
          \def\size{#2}
          % Draw the front face
          \fill[blue!20] (0,0,0) -- (0,\size,0) -- (\size, \size,0) -- (\size,0,0) -- cycle;
          % Draw the top face
          \fill[blue!40] (0,\size,0) -- (0,\size,\size) -- (\size, \size, \size) -- (\size, \size,0) -- cycle;
          % Draw the right face
          \fill[blue!60] (\size,0,0) -- (\size,0,\size) -- (\size, \size, \size) -- (\size, \size,0) -- cycle;
  
          \fill[red!30] (1,1,0) -- (1,\size-1,0) -- (\size-1, \size-1,0) -- (\size-1,1,0) -- cycle;
          \fill[red!40] (1,\size,1) -- (1,\size,\size-1) -- (\size-1, \size, \size-1) -- (\size-1, \size,1) -- cycle;
          \fill[red!45] (\size,1,1) -- (\size,1,\size-1) -- (\size, \size-1, \size-1) -- (\size, \size-1,1) -- cycle;
  
          % Draw the grid
          \foreach \x in {0,1,...,\size} {
            \draw[black] (\x,0,0) -- (\x,\size,0);
            \draw[black] (0,\x,0) -- (\size,\x,0);

            \draw[black] (\size,\x,0) -- (\size,\x,\size);
            \draw[black] (\size,0,\x) -- (\size, \size,\x);

            \draw[black] (\x,\size,0) -- (\x,\size,\size);
            \draw[black] (0,\size,\x) -- (\size, \size,\x);
          }
        \end{scope}
      }
  
      % Draw the first cube at (0,0) with size 8
      \drawcube{(0em, 0em)}{10}
      \drawcube{(18em, 0em)}{10}
      \drawcube{(0em, 15em)}{10}
      \drawcube{(18em, 15em)}{10}
        
      \node[draw, minimum width = 3em, minimum height = 1.5em, align=center] at (14em,12em) {MPI Communications};
    
      \fill[red] (14em,12em) circle (3pt);
      \fill[red] (14em,4em) circle (3pt);
      \fill[red] (14em,20em) circle (3pt);

      \fill[red] (4em,12em) circle (3pt);
      \fill[red] (22em,12em) circle (3pt);
    \end{tikzpicture}  
  \caption{A 3D MPI Communication Scheme of $8$ processors between $3$ dimension matrices.}
  \label{FIG_MPI_3D_Example_SCHEME}
\end{figure}


\subsection{Template Distributed Multi-dimension Matrix Design}
\subsubsection{Detail Object Design}
Adhering to the STL safety routines, I chose to create detail template class object, hidden from users,
named \texttt{\_\_array\_Cart<class \_\_T, \_\_size\_type \_\_NumD>}.
Here, the \texttt{\_\_T} represents the value type, \texttt{\_\_size\_type} specifies the type of number of dimensions.
Since it is internal and not exposed from users, I decided to directly use other detail objects as member variables rather than 
smart pointers.
In this context, Cartesian matrix has public member variables \texttt{\_\_array} and \texttt{topology::Cartesian},
and provides memory operations. 
This approach enhances both performance both performance and simplicity by avoiding unnecessary abstractions in the internal design 
while maintain a robust memory management.

\paragraph{Distributed operator <<}
The STL os stream operator \texttt{<<} prints the matrices of all processes in sequence which build on multidimensional matrix's. 
Thus the Unix standard \texttt{fflush} function is utilized for flushing the cache in terminal, to ensure the stdout is print immediately.

\subsubsection{User Interface Design}
The \texttt{array\_Cart<class T, size\_type NumD>} is an object exposed to users, whereas only provides limited access to member variables.



% \subsubsection{Pure Message Passing Parallel}
% \subsubsection{Hybrid Parallel}

\subsection{Physics Informed Neural Networks}
\subsubsection{CUDA parallel}
\subsubsection{Hybrid Parallel}
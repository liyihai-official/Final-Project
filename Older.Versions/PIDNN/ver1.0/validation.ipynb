{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d79b1-690e-4403-a171-45b32cf48264",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae6e9e8-55b7-4877-99f9-7b59e1c89327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "class dense(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_outputs):\n",
    "        super(dense, self).__init__(name='Dense')\n",
    "        self.num_outputs = num_outputs\n",
    "        self.bn = BatchNormalization(momentum=0.1)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\"kernel\",\n",
    "                                     shape = [int(input_shape[-1]),\n",
    "                                             self.num_outputs])\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return  self.bn(tf.matmul(inputs, self.kernel))\n",
    "        \n",
    "\n",
    "class My_fnn(Model):\n",
    "    def __init__(self, neurons):\n",
    "        super().__init__()\n",
    "        self.activations = []\n",
    "        self.custom_layers = []\n",
    "        self.neurons = neurons\n",
    "\n",
    "        for i, neu in enumerate(neurons):\n",
    "            layer = dense(neu)\n",
    "            activation = tf.nn.tanh if i < len(neurons) - 1 else tf.identity\n",
    "            self.activations.append(activation)\n",
    "            self.custom_layers.append(layer)\n",
    "        self.bn = BatchNormalization(momentum=0.1)\n",
    "    \n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.bn(input_tensor)\n",
    "        for i in range(len(self.neurons)):\n",
    "            x = self.custom_layers[i](x)\n",
    "            x = self.activations[i](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8642cba-023e-485b-9189-235d2f7864bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = My_fnn([102,100+2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f66223-99db-4b26-bce7-c67a26b92951",
   "metadata": {},
   "source": [
    "创建损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b48d8d-102a-4683-a423-e0c8f459978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom loss function\n",
    "def custom_loss(model, x, y, training):\n",
    "    y_ = model(x, training=training)\n",
    "    \n",
    "    return tf.reduce_mean((y_- y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404f5ee6-b6ab-4ac6-8f40-9a40723ce325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the gradient function\n",
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = custom_loss(model, inputs, targets, training = True)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06cb3c3-9695-407b-a91b-3248f129aac7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e0443e-6f17-4cfa-925d-632cb1ff682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = tf.keras.optimizers.legacy.Adam(1e-3)\n",
    "# Compile the model\n",
    "# lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=lr_boundaries, values=lr_values)\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=1e-3)\n",
    "    \n",
    "model.compile(optimizer=optimizer, loss=custom_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe062fe4-66eb-4331-ba08-ddb62353393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_err(model, x, u_reference, mc_rounds):\n",
    "    l1_err, l2_err, li_err = 0., 0., 0.\n",
    "    rel_l1_err, rel_l2_err, rel_li_err = 0., 0., 0.\n",
    "    \n",
    "    for _ in range(mc_rounds):\n",
    "        u_approx = model(x, training=False)\n",
    "        err = tf.abs(u_approx - u_reference)\n",
    "        \n",
    "        l1_err += tf.reduce_mean(err)\n",
    "        l2_err += tf.reduce_mean(err**2)\n",
    "        li_err = tf.maximum(li_err, tf.reduce_mean(err))\n",
    "        \n",
    "        rel_err = err / tf.maximum(u_reference, 1e-8)\n",
    "        rel_l1_err += tf.reduce_mean(rel_err)\n",
    "        rel_l2_err += tf.reduce_mean(rel_err**2)\n",
    "        rel_li_err = tf.maximum(rel_li_err, tf.reduce_max(rel_err))\n",
    "    \n",
    "    l1_err /= mc_rounds\n",
    "    l2_err = np.sqrt(l2_err / mc_rounds)\n",
    "    rel_l1_err /= mc_rounds\n",
    "    rel_l2_err = np.sqrt(rel_l2_err / mc_rounds)\n",
    "    \n",
    "    return err, l1_err, l2_err, li_err, rel_l1_err, rel_l2_err, rel_li_err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad22a91-88ff-4dfd-a287-cba2f379ccd1",
   "metadata": {},
   "source": [
    "# 训练初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be86ec8d-7c70-403e-8db8-cd9f38b120d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = tf.float32\n",
    "\n",
    "T, N, d = 1., 1, 100\n",
    "batch_size = 8192\n",
    "\n",
    "neurons = [d+100, d+100, 1]\n",
    "training_steps = 75000\n",
    "\n",
    "mc_rounds, mc_freq = 10, 100 # Monte Carlo Methods\n",
    "\n",
    "xi = tf.random.uniform(shape=(batch_size, d), \n",
    "                      minval=0.,\n",
    "                      maxval=1,\n",
    "                      dtype=dtype)\n",
    "\n",
    "# u_reference = np.sum(np.sin(xi), axis=1).reshape(-1,1) + 1\n",
    "\n",
    "\n",
    "def phi(x):\n",
    "    # Compute the sum of squared elements along axis 1\n",
    "    result = tf.reduce_sum(x ** 2, axis=1, keepdims=True)\n",
    "    \n",
    "    # Cast the result to tf.float32\n",
    "    return tf.cast(result, tf.float32)\n",
    "\n",
    "u_reference = phi(xi) + 2.*T*d\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de40b6f-4685-407f-96a0-de9cf779c8ab",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea3a955-440d-4759-8b3a-6c2d18e55724",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = training_steps\n",
    "file_name = \"draft4.txt\"\n",
    "l = []\n",
    "# Open the file for writing results\n",
    "with open(file_name, 'w') as file_out:\n",
    "    file_out.write('step,err,l1_err,l2_err,li_err,l1_rel,l2_rel,li_rel,learning_rate,time_train,time_mc\\n')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "    \n",
    "        loss_value, grads = grad(model, xi, u_reference)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "        l.append(loss_value.numpy())\n",
    "\n",
    "        if (epoch+1)%mc_freq == 0:\n",
    "            t1_training = time.time()\n",
    "            err, l1_err, l2_err, li_err, rel_l1_err, rel_l2_err, rel_li_err = approx_err(model, xi, u_reference, mc_rounds)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            current_lr = 1e-3\n",
    "\n",
    "            # Write results to file\n",
    "            file_out.write(f'{epoch+1}, {tf.reduce_max(err)}, {l1_err}, {l2_err}, {li_err}, {rel_l1_err}, {rel_l2_err}, {rel_li_err}, {current_lr}, {t1_training - start_time}, {end_time - t1_training}\\n')\n",
    "            file_out.flush()\n",
    "        \n",
    "            print(epoch+1, current_lr, loss_value.numpy(), rel_li_err.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42250656-5994-4370-ad94-8e5dc72d2815",
   "metadata": {},
   "source": [
    "# 可视化 训练结果 误差 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235dc147-2fcb-46f3-ad8a-f312426c80e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3907d5-f203-4781-a575-9d7ae9eea794",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"draft4.txt\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2950bfc-9b1d-4022-b1cc-503568a22b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(dpi = 150, figsize = (10,5))\n",
    "plt.plot(df[\"step\"], df[\"l1_rel\"], c = 'r', label = \"L1 Error\")\n",
    "plt.plot(df[\"step\"], df[\"l2_rel\"], c = 'g', label = \"L2 Error\")\n",
    "plt.plot(df[\"step\"], df[\"li_rel\"], c = 'b', label = \"Inf Error\")\n",
    "# plt.ylim([0,2])\n",
    "# plt.xlim([0,3e5])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d5cc98-b81d-4f6a-b8b7-33117d08bed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df57cfda-fba1-4e09-9fc9-ffe4c68eb93f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b7e17f-19ad-48f0-8b13-279def3a0eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "161d116e-858b-41ad-80a3-88cb7bdbf799",
   "metadata": {},
   "source": [
    "# 预测 与 参考值可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514831f4-47d3-45c6-940a-02b95c509875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the grid coordinates\n",
    "xx = np.linspace(0,1,50)\n",
    "yy = np.linspace(0,1,50)\n",
    "\n",
    "# Create a meshgrid from the coordinates\n",
    "X, Y = np.meshgrid(xx, yy)\n",
    "\n",
    "grid_array = np.column_stack((X.ravel(), Y.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426385ae-c56c-44d2-9f68-6021bbec35b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uu = np.sum(np.sin(grid_array), axis=1) + 1\n",
    "uu = phi(grid_array) + 2.*T*d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf46a39-1b68-4bf0-9dc8-b01fc427d67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3D plot\n",
    "fig = plt.figure(figsize=(15,5), dpi=200)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter plot with color based on function values\n",
    "scatter = ax.scatter(grid_array[:,0], grid_array[:,1], uu, c=uu, cmap='viridis', marker='+',alpha=0.3)\n",
    "\n",
    "\n",
    "# Add colorbar to show the corresponding function values\n",
    "cbar = fig.colorbar(scatter, ax=ax, label='u(1, x, y)')\n",
    "\n",
    "scatter = ax.scatter(grid_array[:,0], grid_array[:,1], model(grid_array, training=False), alpha=0.2,cmap='viridis', marker='+', c = 'r')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_ylabel('Y-axis')\n",
    "ax.set_zlabel('Function Value')\n",
    "ax.set_title('u(1,x,y)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f43427a-a04d-4386-a1bc-9ebfa84dc39b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
